name: Orchestrator Pipeline

on:
  push:
    branches: [ master, develop, feature/*, release/* ]
  pull_request:
    branches: [ master, develop ]
  workflow_dispatch:

permissions:
  contents: write
  packages: write
  security-events: write
  pull-requests: write
  issues: write

env:
  NODE_VERSION: '20.x'
  SONAR_PROJECT_KEY: github_poc-task-manager-herooffer-ghc
  SONAR_ORG: luanagithub

concurrency:
  group: ci-${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  lint:
    name: Lint
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: npm
          cache-dependency-path: |
            package-lock.json
            backend/package-lock.json
            frontend/package-lock.json
      - name: Install root + workspaces deps (peer-safe)
        run: |
          set -e
          echo "Installing root devDependencies (eslint & plugins) + workspaces with legacy peer fallback.";
          if [ -f package-lock.json ]; then
            npm ci || echo "npm ci failed -> fallback";
          fi
          if [ ! -d node_modules ]; then
            npm install --legacy-peer-deps
          fi
          # Ensure workspace deps too (will respect lockfile entries)
            npm install --workspaces --legacy-peer-deps
          echo "Installed packages:"; ls -1 node_modules | head -n 30 || true
          echo "Node $(node -v) - npm $(npm -v)"
      - name: Lint (flat config)
        run: |
          npx eslint backend frontend

  typecheck:
    name: Type Check (Frontend)
    runs-on: ubuntu-latest
    needs: [lint]
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: npm
          cache-dependency-path: frontend/package-lock.json
      - name: Install frontend deps
        working-directory: frontend
        run: |
          (npm ci || npm install --legacy-peer-deps)
      - name: TypeScript Check
        working-directory: frontend
        run: npx tsc --noEmit

  test-backend:
    name: Test Backend
    runs-on: ubuntu-latest
    needs: [typecheck]
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: npm
          cache-dependency-path: backend/package-lock.json
      - name: Install backend deps
        working-directory: backend
        run: |
          (npm ci || npm install --legacy-peer-deps)
      - name: Run Backend Tests
        working-directory: backend
        run: |
          npx jest --config jest.config.unit.js --coverage --coverageDirectory coverage-unit --reporters=default \
            --coverageReporters=text --coverageReporters=lcov --coverageReporters=json-summary
          if [ -f jest.config.integration.js ]; then npx jest --config jest.config.integration.js; fi
      - name: Upload Backend Coverage
        uses: actions/upload-artifact@v4
        with:
          name: backend-coverage
          path: backend/coverage-unit/

  test-frontend:
    name: Test Frontend
    runs-on: ubuntu-latest
    needs: [typecheck]
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: npm
          cache-dependency-path: frontend/package-lock.json
      - name: Install frontend deps
        working-directory: frontend
        run: |
          (npm ci || npm install --legacy-peer-deps)
      - name: Run Frontend Tests
        working-directory: frontend
        env:
          CI: true
        run: |
          npm test -- --coverage --watchAll=false \
            --coverageReporters=text --coverageReporters=lcov --coverageReporters=json-summary
      - name: Upload Frontend Coverage
        uses: actions/upload-artifact@v4
        with:
          name: frontend-coverage
          path: frontend/coverage/

  coverage-gate:
    name: Coverage Gate (>=80%)
    runs-on: ubuntu-latest
    needs: [test-backend, test-frontend]
    outputs:
      coverage_avg: ${{ steps.combine.outputs.avg }}
      coverage_gate: ${{ steps.combine.outputs.gate }}
    steps:
      - uses: actions/checkout@v4
      - name: Download Coverage Artifacts
        uses: actions/download-artifact@v4
        with:
          path: coverage-artifacts
      - name: Combine & Enforce Coverage
        id: combine
        run: |
          set -e
          BACK=$(find coverage-artifacts/backend-coverage -maxdepth 2 -name 'coverage-summary.json' | head -n1 || true)
          FRONT=$(find coverage-artifacts/frontend-coverage -maxdepth 2 -name 'coverage-summary.json' | head -n1 || true)
          if [ -z "$BACK" ] || [ -z "$FRONT" ]; then echo "::error::Missing coverage summaries"; exit 1; fi
          export BACK FRONT
          node <<'EOF'
          const fs = require('fs');
          const backend = process.env.BACK;
          const frontend = process.env.FRONT;
          const b = JSON.parse(fs.readFileSync(backend,'utf8'));
          const f = JSON.parse(fs.readFileSync(frontend,'utf8'));
          function merge(a,b){
            // Defensive: ensure numeric
            const at = Number(a.total)||0, bt=Number(b.total)||0, ac=Number(a.covered)||0, bc=Number(b.covered)||0;
            return { total: at+bt, covered: ac+bc };
          }
          const metrics = Object.keys(b.total);
          const result={ total:{} };
          for(const m of metrics){
            const merged=merge(b.total[m], f.total[m]);
            if(merged.total === 0){
              // No items of this metric -> treat as fully covered (neutral) to avoid NaN & not penalize
              merged.pct='100.00';
            } else {
              const pct = (merged.covered/merged.total*100);
              merged.pct = (Number.isFinite(pct)? pct : 0).toFixed(2);
            }
            result.total[m]=merged;
          }
          const thresholds={ lines:80, statements:80, functions:80, branches:80 };
            // Fail list only considers finite percentages
          const fails=Object.entries(thresholds).filter(([k,v])=> {
            const val=parseFloat(result.total[k].pct); return Number.isFinite(val) && val < v;
          }).map(([k])=>k+':'+result.total[k].pct);
          const numericPcts = Object.values(result.total).map(m=>parseFloat(m.pct)).filter(Number.isFinite);
          const avg = (numericPcts.length? (numericPcts.reduce((a,x)=>a+x,0)/numericPcts.length) : 100).toFixed(2);
          fs.mkdirSync('combined-coverage',{recursive:true});
          const avgColor = parseFloat(avg)>=90?'brightgreen':parseFloat(avg)>=80?'green':parseFloat(avg)>=60?'orange':'red';
          fs.writeFileSync('combined-coverage/coverage-badge.json', JSON.stringify({schemaVersion:1,label:'coverage (combined)',message:avg+'%',color: avgColor}));
          const gatePass = fails.length === 0;
          fs.writeFileSync('combined-coverage/coverage-gate-badge.json', JSON.stringify({schemaVersion:1,label:'coverage gate',message: gatePass? 'pass':'fail',color: gatePass? 'green':'red'}));
          fs.writeFileSync('combined-coverage/coverage-metrics.json', JSON.stringify({ avg, metrics: result.total, pass: gatePass, fails }, null, 2));
          fs.appendFileSync(process.env.GITHUB_OUTPUT, `avg=${avg}\n`);
          fs.appendFileSync(process.env.GITHUB_OUTPUT, `gate=${gatePass? 'pass':'fail'}\n`);
          if(fails.length){ console.error('Coverage gate fail:', fails.join(',')); process.exit(1); }
          EOF
      - name: Upload Combined Coverage Artifact
        uses: actions/upload-artifact@v4
        with:
          name: combined-coverage
          path: combined-coverage

  build-backend:
    name: Build Backend
    runs-on: ubuntu-latest
    needs: [coverage-gate]
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: npm
          cache-dependency-path: backend/package-lock.json
      - name: Install backend deps
        working-directory: backend
        run: |
          (npm ci || npm install --legacy-peer-deps)
      - name: Backend smoke
        working-directory: backend
        run: |
          node -c src/server.js 2>/dev/null || echo "(no syntax issues)"
          timeout 5s node src/server.js &
          sleep 2
          echo "Backend started (smoke)"

  build-frontend:
    name: Build Frontend
    runs-on: ubuntu-latest
    needs: [build-backend]
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: npm
          cache-dependency-path: frontend/package-lock.json
      - name: Install frontend deps
        working-directory: frontend
        run: |
          (npm ci || npm install --legacy-peer-deps)
      - name: Build
        working-directory: frontend
        run: |
          if npm run | grep -q build; then npm run build; else echo "(no build script)"; fi

  codeql:
    name: CodeQL Analyze
    runs-on: ubuntu-latest
    needs: [build-frontend]
    permissions:
      contents: read
      security-events: write
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
      - name: Init CodeQL
        uses: github/codeql-action/init@v3
        with:
          languages: javascript
          build-mode: none
        env:
          CODEQL_ACTION_DEBUG: true
      - name: Analyze
        uses: github/codeql-action/analyze@v3
        with:
          category: '/language:javascript'
        env:
          CODEQL_ACTION_DEBUG: true
      - name: CodeQL SARIF existence debug
        run: |
          ls -R ./codeql* || true
          echo "Listing uploaded SARIF (post-action cannot access, but we verify working directory)."


  diff-coverage:
    name: Diff Coverage (changed files)
    runs-on: ubuntu-latest
    needs: [test-backend, test-frontend]
    outputs:
      diff_pct: ${{ steps.diffcalc.outputs.pct }}
      diff_pass: ${{ steps.diffcalc.outputs.pass }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - name: List Changed Files
        id: changed
        run: |
          if [ "${{ github.event_name }}" = "pull_request" ]; then
            BASE_REF="${{ github.event.pull_request.base.ref }}"
            git fetch origin "$BASE_REF:$BASE_REF" || true
            git diff --name-only origin/$BASE_REF...HEAD | grep -E '^(backend|frontend)/src/' || true > changed.txt
          else
            if git rev-parse HEAD~1 >/dev/null 2>&1; then
              git diff --name-only HEAD~1..HEAD | grep -E '^(backend|frontend)/src/' || true > changed.txt
            else
              echo "(No previous commit to diff against)";
              touch changed.txt
            fi
          fi
          echo "Changed files:"; cat changed.txt || true
          printf 'list<<EOF\n' >> $GITHUB_OUTPUT
          cat changed.txt >> $GITHUB_OUTPUT
          printf '\nEOF\n' >> $GITHUB_OUTPUT
      - name: Download Coverage Artifacts
        uses: actions/download-artifact@v4
        with:
          path: diff-cov-artifacts
      - name: Compute Diff Coverage
        id: diffcalc
        run: |
          set -e
          CHANGED="$(cat changed.txt)"
          if [ -z "${CHANGED// /}" ]; then
            echo "No changed source files; marking pass with 100%.";
            mkdir -p diff-coverage
            echo '{"schemaVersion":1,"label":"diff coverage","message":"100%","color":"brightgreen"}' > diff-coverage/diff-coverage-badge.json
            echo "pct=100" >> $GITHUB_OUTPUT; echo "pass=true" >> $GITHUB_OUTPUT; exit 0;
          fi
          echo "Changed files:\n$CHANGED"
          node <<'EOF'
          const fs = require('fs');
          const changedRaw = process.env.CHANGED_LIST.split('\n').filter(Boolean);
          const threshold = parseFloat(process.env.DIFF_THRESHOLD || '80');
          function walk(dir, out=[]) { for (const e of fs.readdirSync(dir,{withFileTypes:true})){ const p=dir+'/'+e.name; if(e.isDirectory()) walk(p,out); else if(e.isFile()&&e.name==='lcov.info') out.push(p);} return out; }
          const lcovFiles = walk('diff-cov-artifacts');
          if(!lcovFiles.length){ fs.appendFileSync(process.env.GITHUB_OUTPUT,'pct=0\npass=false\n'); process.exit(1); }
          let total=0, covered=0;
          for(const file of lcovFiles){
            const data = fs.readFileSync(file,'utf8').split('\n');
            let current=null, lines=[];
            for(const line of data){
              if(line.startsWith('SF:')){ current=line.substring(3).trim(); lines=[]; }
              else if(line.startsWith('DA:')){ const [ln,hits]=line.substring(3).split(','); lines.push({ln:parseInt(ln,10),hits:parseInt(hits,10)}); }
              else if(line==='end_of_record' && current){
                const short=current.replace(/.*(backend|frontend)\//,'$1/');
                if(changedRaw.some(ch=> short.endsWith(ch) || short.includes(ch))){ for(const l of lines){ total++; if(l.hits>0) covered++; } }
                current=null; lines=[];
              }
            }
          }
          const pct = total? (covered/total*100).toFixed(2) : '100';
          const pass = parseFloat(pct) >= threshold;
          fs.mkdirSync('diff-coverage',{recursive:true});
          const color = parseFloat(pct)>=90?'brightgreen':parseFloat(pct)>=threshold?'green':parseFloat(pct)>=60?'orange':'red';
          fs.writeFileSync('diff-coverage/diff-coverage-badge.json', JSON.stringify({schemaVersion:1,label:'diff coverage',message:pct+'%',color}));
          fs.appendFileSync(process.env.GITHUB_OUTPUT, `pct=${pct}\npass=${pass}\n`);
          if(!pass){
            console.error(`Diff coverage below threshold (${threshold}%) -> ${pct}%`);
            process.exit(1);
          }
          EOF
        env:
          CHANGED_LIST: ${{ steps.changed.outputs.list }}
          DIFF_THRESHOLD: 80
        shell: bash
      - name: Upload Diff Coverage Artifact
        uses: actions/upload-artifact@v4
        with:
          name: diff-coverage
          path: diff-coverage
  sbom:
    name: SBOM (CycloneDX)
    runs-on: ubuntu-latest
    needs: [build-frontend]
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
      - name: Generate SBOM backend
        working-directory: backend
        run: |
          (npm ci || npm install --legacy-peer-deps)
          npx @cyclonedx/cyclonedx-npm --json --output ../sbom-backend.json || npx cyclonedx-npm --json --output ../sbom-backend.json || echo "(fallback)"
      - name: Generate SBOM frontend
        working-directory: frontend
        run: |
          (npm ci || npm install --legacy-peer-deps)
          npx @cyclonedx/cyclonedx-npm --json --output ../sbom-frontend.json || npx cyclonedx-npm --json --output ../sbom-frontend.json || echo "(fallback)"
      - name: Package SBOMs
        run: |
          mkdir -p sbom
          mv sbom-backend.json sbom/backend.json 2>/dev/null || true
          mv sbom-frontend.json sbom/frontend.json 2>/dev/null || true
          BACK_OK=false; FRONT_OK=false
          [ -f sbom/backend.json ] && BACK_OK=true
          [ -f sbom/frontend.json ] && FRONT_OK=true
          if $BACK_OK && $FRONT_OK; then
            node -e "const fs=require('fs');const back=JSON.parse(fs.readFileSync('sbom/backend.json','utf8'));const front=JSON.parse(fs.readFileSync('sbom/frontend.json','utf8'));const combined={bomFormat:'CycloneDX',specVersion:back.specVersion||front.specVersion||'1.5',version:1,metadata:{tools:[...(back.metadata?.tools||[]),...(front.metadata?.tools||[])]},components:[...(back.components||[]),...(front.components||[])]};fs.writeFileSync('sbom/combined.json',JSON.stringify(combined,null,2));console.log('Combined SBOM written to sbom/combined.json');"
          elif $BACK_OK && ! $FRONT_OK; then
            echo "Frontend SBOM missing; using backend SBOM as combined.";
            cp sbom/backend.json sbom/combined.json
          elif $FRONT_OK && ! $BACK_OK; then
            echo "Backend SBOM missing; using frontend SBOM as combined.";
            cp sbom/frontend.json sbom/combined.json
          else
            echo "No SBOM files generated; creating placeholder.";
            echo '{"bomFormat":"CycloneDX","specVersion":"1.5","version":1,"metadata":{"tools":[]},"components":[]}' > sbom/combined.json
          fi
          # Add a lightweight index for quick inspection
          echo "SBOM files:" > sbom/index.txt
          ls -1 sbom >> sbom/index.txt || true
          ls -l sbom
      - name: Upload SBOM
        uses: actions/upload-artifact@v4
        with:
          name: sbom
          path: sbom
  sonar:
    name: SonarCloud
    runs-on: ubuntu-latest
    needs: [build-frontend]
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
      - name: Guard (skip if secret missing or external PR)
        id: sonar_guard
        run: |
          if [ "${{ github.event_name }}" = "pull_request" ] && [ "${{ github.event.pull_request.head.repo.full_name }}" != "${{ github.repository }}" ]; then
            echo "SKIP=true" >> $GITHUB_OUTPUT
            echo "::warning::External PR (fork) - skipping Sonar.";
            exit 0
          fi
          if [ -z "${{ secrets.SONAR_TOKEN }}" ]; then
            echo "SKIP=true" >> $GITHUB_OUTPUT
            echo "::warning::SONAR_TOKEN missing - skipping Sonar.";
          else
            echo "SKIP=false" >> $GITHUB_OUTPUT
          fi
      - name: SonarCloud Scan
        if: steps.sonar_guard.outputs.SKIP == 'false'
        uses: SonarSource/sonarcloud-github-action@v2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}
        with:
          args: >-
            -Dsonar.projectKey=${{ env.SONAR_PROJECT_KEY }}
            -Dsonar.organization=${{ env.SONAR_ORG }}
            -Dsonar.sources=backend/src,frontend/src
            -Dsonar.exclusions=**/node_modules/**,**/coverage/**
            -Dsonar.javascript.lcov.reportPaths=backend/coverage-unit/lcov.info,frontend/coverage/lcov.info
            -Dsonar.coverage.exclusions=**/*.test.*,**/tests/**,**/coverage/**,**/jest.config*.js
      - name: Check Quality Gate
        if: steps.sonar_guard.outputs.SKIP == 'false'
        run: |
          sleep 10
          STATUS=$(curl -s -u "${{ secrets.SONAR_TOKEN }}:" "https://sonarcloud.io/api/qualitygates/project_status?projectKey=${{ env.SONAR_PROJECT_KEY }}" | jq -r '.projectStatus.status')
          echo "Quality Gate Status: $STATUS"
          if [ "$STATUS" != "OK" ] && [ "$STATUS" != "SUCCESS" ]; then
            echo "::error::Quality Gate failed ($STATUS)"; exit 1; fi
      - name: Sonar Summary
        run: |
          if [ "${{ steps.sonar_guard.outputs.SKIP }}" = "true" ]; then
            echo "### SonarCloud" >> $GITHUB_STEP_SUMMARY
            echo "Skipped (fork or missing secret)." >> $GITHUB_STEP_SUMMARY
          else
            echo "### SonarCloud" >> $GITHUB_STEP_SUMMARY
            echo "Analysis executed." >> $GITHUB_STEP_SUMMARY
          fi
  semgrep:
    name: Semgrep SAST
    runs-on: ubuntu-latest
    needs: [build-frontend]
    steps:
      - uses: actions/checkout@v4
      - name: Run Semgrep (ci ruleset)
        uses: returntocorp/semgrep-action@v1
        with:
          config: p/ci
      - name: Semgrep Summary
        run: |
          echo "### Semgrep" >> $GITHUB_STEP_SUMMARY
          echo "Executed (ci rules)." >> $GITHUB_STEP_SUMMARY
      - name: Generate Semgrep SARIF
        run: |
          pip install --no-cache-dir semgrep
          semgrep --config p/ci --sarif --output semgrep.sarif || { echo "Semgrep SARIF generation failed"; exit 1; }
          ls -l semgrep.sarif || true
      - name: Upload Semgrep SARIF to Code Scanning
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: semgrep.sarif
      - name: Upload Semgrep SARIF Artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: semgrep-sarif
          path: semgrep.sarif

  package-backend:
    name: Build & Publish Backend Image (GHCR)
    runs-on: ubuntu-latest
    needs: [build-backend]
    if: github.ref == 'refs/heads/master' || github.ref == 'refs/heads/develop'
    permissions:
      contents: read
      packages: write
    steps:
      - uses: actions/checkout@v4
      - name: Login to GHCR
        run: echo "${{ secrets.GITHUB_TOKEN }}" | docker login ghcr.io -u ${{ github.actor }} --password-stdin
      - name: Build & Push Image
        env:
          IMAGE_NAME: ghcr.io/${{ github.repository_owner }}/poc-task-manager-backend
        run: |
          TAG=$(echo "$GITHUB_REF_NAME" | tr '/' '-')
          docker build -t $IMAGE_NAME:$TAG backend
          docker push $IMAGE_NAME:$TAG
          echo "Image pushed: $IMAGE_NAME:$TAG"

  deploy-qa:
    name: Deploy QA (Demo)
    runs-on: ubuntu-latest
    needs: [build-backend, build-frontend, coverage-gate, codeql, semgrep, sonar]
    if: github.ref == 'refs/heads/develop'
    environment:
      name: QA
      url: https://example-qa.invalid
    steps:
      - name: Simulated QA Deploy
        run: |
          echo "(Demo) Deploying to QA environment..."
          echo "This is a placeholder deploy step for gating demonstration." 

  deploy-prd:
    name: Deploy Production (Demo)
    runs-on: ubuntu-latest
    needs: [build-backend, build-frontend, coverage-gate, codeql, semgrep, sonar]
    if: github.ref == 'refs/heads/master'
    environment:
      name: PRD
      url: https://example-prod.invalid
    steps:
      - name: Simulated Production Deploy
        run: |
          echo "(Demo) Deploying to Production environment..."
          echo "This is a placeholder deploy step for gating demonstration." 
  finalize:
    name: Finalize Summary
    runs-on: ubuntu-latest
    needs: [lint, typecheck, test-backend, test-frontend, coverage-gate, build-backend, build-frontend, codeql, sonar, diff-coverage, sbom, semgrep]
    if: always()
    steps:
      - name: Summary
        run: |
          echo "### Pipeline Orchestrator" >> $GITHUB_STEP_SUMMARY
          echo "Lint: ${{ needs.lint.result }}" >> $GITHUB_STEP_SUMMARY
          echo "Typecheck: ${{ needs.typecheck.result }}" >> $GITHUB_STEP_SUMMARY
          echo "Backend Tests: ${{ needs['test-backend'].result }}" >> $GITHUB_STEP_SUMMARY
          echo "Frontend Tests: ${{ needs['test-frontend'].result }}" >> $GITHUB_STEP_SUMMARY
          echo "Coverage Gate: ${{ needs['coverage-gate'].result }} (avg=${{ needs['coverage-gate'].outputs.coverage_avg }} gate=${{ needs['coverage-gate'].outputs.coverage_gate }})" >> $GITHUB_STEP_SUMMARY
          echo "Build Backend: ${{ needs['build-backend'].result }}" >> $GITHUB_STEP_SUMMARY
          echo "Build Frontend: ${{ needs['build-frontend'].result }}" >> $GITHUB_STEP_SUMMARY
          echo "CodeQL: ${{ needs.codeql.result }}" >> $GITHUB_STEP_SUMMARY
          echo "Sonar: ${{ needs.sonar.result }}" >> $GITHUB_STEP_SUMMARY
          if [ "${{ needs.diff-coverage.result }}" != "skipped" ]; then echo "Diff Coverage: ${{ needs['diff-coverage'].result }} (pct=${{ needs['diff-coverage'].outputs.diff_pct || 'n/a' }})" >> $GITHUB_STEP_SUMMARY; fi
          echo "SBOM: ${{ needs.sbom.result }}" >> $GITHUB_STEP_SUMMARY
      - name: Checkout (for badges)
        if: github.event_name == 'push'
        uses: actions/checkout@v4
      - name: Download Combined Coverage Artifact
        if: github.event_name == 'push'
        uses: actions/download-artifact@v4
        with:
          name: combined-coverage
          path: combined-coverage
      - name: Download Diff Coverage Artifact
        if: github.event_name == 'push'
        uses: actions/download-artifact@v4
        with:
          name: diff-coverage
          path: diff-coverage
      - name: Download Semgrep SARIF Artifact
        if: github.event_name == 'push'
        uses: actions/download-artifact@v4
        with:
          name: semgrep-sarif
          path: semgrep-artifact
      - name: Collect Security Signals (severity & aging)
        if: github.event_name == 'push'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -e
          REPO="${GITHUB_REPOSITORY}"
          echo "Collecting Code Scanning alerts (CodeQL + Semgrep uploaded)";
          # Code Scanning Alerts (open)
          CODE_SCANNING_JSON=$(curl -s -H "Authorization: Bearer $GITHUB_TOKEN" -H "Accept: application/vnd.github+json" "https://api.github.com/repos/$REPO/code-scanning/alerts?state=open&per_page=100") || CODE_SCANNING_JSON='[]'
          echo "$CODE_SCANNING_JSON" | jq '.' >/dev/null 2>&1 || CODE_SCANNING_JSON='[]'
          CRIT=$(echo "$CODE_SCANNING_JSON" | jq '[.[] | select(.security_severity_level=="critical")] | length')
          HIGH=$(echo "$CODE_SCANNING_JSON" | jq '[.[] | select(.security_severity_level=="high")] | length')
          MED=$(echo "$CODE_SCANNING_JSON" | jq '[.[] | select(.security_severity_level=="medium")] | length')
          LOW=$(echo "$CODE_SCANNING_JSON" | jq '[.[] | select(.security_severity_level=="low")] | length')
          # Semgrep SARIF results severity fallback (if not surfaced in code scanning metadata)
          if [ -f semgrep-artifact/semgrep.sarif ]; then
            SEMGREP_CRIT=$(jq '[.runs[].results[] | select(.rule.severity=="ERROR")]|length' semgrep-artifact/semgrep.sarif 2>/dev/null || echo 0)
            SEMGREP_HIGH=$(jq '[.runs[].results[] | select(.rule.severity=="WARNING")]|length' semgrep-artifact/semgrep.sarif 2>/dev/null || echo 0)
            SEMGREP_MED=$(jq '[.runs[].results[] | select(.rule.severity=="INFO")]|length' semgrep-artifact/semgrep.sarif 2>/dev/null || echo 0)
            # Merge (sum) if GitHub code scanning did not map them
            CRIT=$((CRIT+SEMGREP_CRIT))
            HIGH=$((HIGH+SEMGREP_HIGH))
            MED=$((MED+SEMGREP_MED))
          fi
          mkdir -p badges/history
          CATALOG=badges/history/alerts-catalog.json
          NOW_TS=$(date +%s)
          node <<'EOF'
          const fs=require('fs');
          const now=parseInt(process.env.NOW_TS,10);
          const catalogFile=process.env.CATALOG;
          let catalog={};
            try{ catalog=JSON.parse(fs.readFileSync(catalogFile,'utf8')); }catch{}
          // Build set of current alert IDs from code scanning
          let currentIds=new Set();
          try {
            const alerts = JSON.parse(process.env.CODE_SCANNING_JSON || '[]');
            for(const a of alerts){
              const id = `cs:${a.number||a.rule?.id||'unknown'}`;
              currentIds.add(id);
              if(!catalog[id]) catalog[id]={ firstSeen: now };
            }
          } catch(e){ /* ignore */ }
          // Semgrep SARIF granular IDs
          try {
            if(fs.existsSync('semgrep-artifact/semgrep.sarif')){
              const sarif=JSON.parse(fs.readFileSync('semgrep-artifact/semgrep.sarif','utf8'));
              for(const run of sarif.runs||[]){
                for(const r of run.results||[]){
                  const loc=(r.locations&&r.locations[0]&&r.locations[0].physicalLocation)||{};
                  const file=loc.artifactLocation?.uri||'unknown';
                  const line=loc.region?.startLine||0;
                  const ruleId=r.ruleId||'rule';
                  const id=`sg:${ruleId}:${file}:${line}`;
                  currentIds.add(id);
                  if(!catalog[id]) catalog[id]={ firstSeen: now };
                }
              }
            }
          } catch(e){ /* ignore */ }
          // Aging calc (only open alerts we still see)
          let ages=[];
          for(const id of currentIds){
            const meta=catalog[id];
            if(meta && meta.firstSeen){
              const ageDays=(now - meta.firstSeen)/86400;
              ages.push(ageDays);
            }
          }
          const agingDays = ages.length? (ages.reduce((a,b)=>a+b,0)/ages.length) : 0;
          fs.writeFileSync(catalogFile, JSON.stringify(catalog,null,2));
          // Export summary JSON
          const summary={ critical: parseInt(process.env.CRIT,10)||0, high: parseInt(process.env.HIGH,10)||0, medium: parseInt(process.env.MED,10)||0, low: parseInt(process.env.LOW,10)||0, agingDays: parseFloat(agingDays.toFixed(2)) };
          fs.writeFileSync('badges/security-signals.json', JSON.stringify(summary,null,2));
          // Write env file append for next step
          fs.appendFileSync(process.env.GITHUB_ENV, `CRIT_COUNT=${summary.critical}\nHIGH_COUNT=${summary.high}\nMED_COUNT=${summary.medium}\nAGING_DAYS=${summary.agingDays}\n`);
          EOF
          echo "Security signals collected: CRIT=$CRIT HIGH=$HIGH MED=$MED LOW=$LOW"
          # Keep raw JSON for node script
          printf '%s' "$CODE_SCANNING_JSON" > code-scanning-alerts.json
          # Persist env counts for node (added inside node too for redundancy)
          echo "CRIT_COUNT=$CRIT" >> $GITHUB_ENV
          echo "HIGH_COUNT=$HIGH" >> $GITHUB_ENV
          echo "MED_COUNT=$MED" >> $GITHUB_ENV
          echo "LOW_COUNT=$LOW" >> $GITHUB_ENV
          # Aging already appended by node
      - name: Publish Badges (push events only)
        if: github.event_name == 'push'
        run: |
          set -e
          SAFE_BRANCH=$(echo "${GITHUB_REF_NAME}" | tr '/' '-' | tr '[:upper:]' '[:lower:]')
          mkdir -p badges/history
          ########################################################################
          # Risk Score (heurística estendida)                                    #
          # Objetivo: síntese executiva de risco técnico.                        #
          # Fórmula (base 100 - penalidades):                                    #
          #  Coverage gate fail: -30                                             #
          #  Cobertura média <85: -10 | [85,90): -5                              #
          #  Diff coverage <80: -15 | [80,90): -5                                #
          #  CodeQL não success: -15                                             #
          #  Semgrep não success: -10                                            #
          #  Sonar não success: -10                                              #
          #  ALERTAS (SARIF + Sonar) severidade: Critical:-12 High:-8 Medium:-4  #
          #  Aging médio (dias) alertas (se disponível):                         #
          #     >14d:-10  >7d:-6  >3d:-3                                         #
          #  Penalização máxima combinada por severidades limitada a 40          #
          #  Clamped 0..100                                                      #
          # Observação: Aging / severidades obtidos de artefatos se presentes;   #
          # caso contrário, assumidos como zero (não penaliza).                  #
          ########################################################################
          COV_AVG="${{ needs['coverage-gate'].outputs.coverage_avg }}"
          COV_GATE="${{ needs['coverage-gate'].outputs.coverage_gate }}"
          DIFF_PCT="${{ needs['diff-coverage'].outputs.diff_pct }}"
          CODEQL_RESULT="${{ needs.codeql.result }}"
            SONAR_RESULT="${{ needs.sonar.result }}"
          SEMGREP_RESULT="${{ needs.semgrep.result }}"
          risk=100
          # Coverage gate
          if [ "${COV_GATE}" = "fail" ]; then risk=$((risk-30)); fi
          # Coverage average numeric check
          if echo "$COV_AVG" | grep -Eq '^[0-9]+(\.[0-9]+)?$'; then
            cov_int=${COV_AVG%.*}
            awk 'BEGIN{exit !( '$COV_AVG' < 85 )}' || risk=$((risk-10))
            awk 'BEGIN{exit !( '$COV_AVG' >= 85 && '$COV_AVG' < 90 )}' && risk=$((risk-5)) || true
          fi
          # Diff coverage
          if echo "$DIFF_PCT" | grep -Eq '^[0-9]+(\.[0-9]+)?$'; then
            awk 'BEGIN{exit !( '$DIFF_PCT' < 80 )}' || risk=$((risk-15))
            awk 'BEGIN{exit !( '$DIFF_PCT' >= 80 && '$DIFF_PCT' < 90 )}' && risk=$((risk-5)) || true
          fi
          # Tool results (treat success vs others)
          [ "$CODEQL_RESULT" = "success" ] || risk=$((risk-15))
          [ "$SEMGREP_RESULT" = "success" ] || risk=$((risk-10))
          [ "$SONAR_RESULT" = "success" ] || risk=$((risk-10))
          # Clamp
          if [ $risk -lt 0 ]; then risk=0; fi
          if [ $risk -gt 100 ]; then risk=100; fi
          # Color scale
          if [ $risk -ge 90 ]; then RISK_COLOR=brightgreen; elif [ $risk -ge 75 ]; then RISK_COLOR=green; elif [ $risk -ge 60 ]; then RISK_COLOR=yellow; elif [ $risk -ge 40 ]; then RISK_COLOR=orange; else RISK_COLOR=red; fi
          mkdir -p badges
          # --- Coleta simplificada de severidades (placeholders se SARIF/sonar summary indisponíveis) ---
          critical=${CRIT_COUNT:-0}; high=${HIGH_COUNT:-0}; medium=${MED_COUNT:-0}
          aging_days=${AGING_DAYS:-0}
          sev_penalty=0
          sev_penalty=$((sev_penalty + critical*12 + high*8 + medium*4))
          if [ $sev_penalty -gt 40 ]; then sev_penalty=40; fi
          risk=$((risk - sev_penalty))
          if [ $aging_days -gt 14 ]; then risk=$((risk-10)); elif [ $aging_days -gt 7 ]; then risk=$((risk-6)); elif [ $aging_days -gt 3 ]; then risk=$((risk-3)); fi
          if [ $risk -lt 0 ]; then risk=0; fi
          if [ $risk -gt 100 ]; then risk=100; fi
          # Color scale
          if [ $risk -ge 90 ]; then RISK_COLOR=brightgreen; elif [ $risk -ge 75 ]; then RISK_COLOR=green; elif [ $risk -ge 60 ]; then RISK_COLOR=yellow; elif [ $risk -ge 40 ]; then RISK_COLOR=orange; else RISK_COLOR=red; fi
          mkdir -p badges
          echo '{"schemaVersion":1,"label":"risk score","message":"'"$risk"'","color":"'"$RISK_COLOR"'"}' > badges/risk-score-badge.json
          # Branch-qualified copy (para deltas futuros)
          cp badges/risk-score-badge.json badges/risk-score-badge-${SAFE_BRANCH}.json || true
          # Histórico de risk score
          RISK_HISTORY=badges/history/risk-score-history-${SAFE_BRANCH}.json
          node - <<'EOF'
          const fs=require('fs');
          const file=process.env.RISK_HISTORY;
          let data=[]; try{ data=JSON.parse(fs.readFileSync(file,'utf8')); }catch{}
          const risk=parseInt(process.env.RISK_VALUE,10);
          const breakdownFile=`badges/risk-score-latest-${process.env.SAFE_BRANCH}.json`;
          // Breakdown components (rough - some variables passed by env)
          const comp={
            coverageGate: process.env.COV_GATE==='fail'? -30:0,
            coverageAvg: (()=>{ const v=parseFloat(process.env.COV_AVG||'0'); if(!Number.isFinite(v)) return 0; if(v<85) return -10; if(v<90) return -5; return 0; })(),
            diffCoverage: (()=>{ const v=parseFloat(process.env.DIFF_PCT||'0'); if(!Number.isFinite(v)) return 0; if(v<80) return -15; if(v<90) return -5; return 0; })(),
            codeql: process.env.CODEQL_RESULT==='success'?0:-15,
            semgrep: process.env.SEMGREP_RESULT==='success'?0:-10,
            sonar: process.env.SONAR_RESULT==='success'?0:-10,
            severities: parseInt(process.env.SEV_PENALTY||'0',10)||0,
            aging: (()=>{ const a=parseFloat(process.env.AGING_DAYS||'0'); if(a>14) return -10; if(a>7) return -6; if(a>3) return -3; return 0; })()
          };
          const totalPen=Object.values(comp).reduce((a,b)=>a+b,0);
          const snapshot={ score:risk, components:comp, totalPenalty: totalPen, generatedAt: new Date().toISOString() };
          fs.writeFileSync(breakdownFile, JSON.stringify(snapshot,null,2));
          if(Number.isFinite(risk)){
            data.push({t:Math.floor(Date.now()/1000),score:risk});
            data=data.slice(-199);
            fs.writeFileSync(file, JSON.stringify(data,null,2));
          }
          EOF
          echo "Generated risk-score-badge.json (risk=$risk color=$RISK_COLOR sevPenalty=$sev_penalty aging=$aging_days)"
          export RISK_VALUE=$risk
          if [ -f diff-coverage/diff-coverage-badge.json ]; then
            DIFF_PCT=$(jq -r '.message' diff-coverage/diff-coverage-badge.json 2>/dev/null | tr -d '%')
            if [ -n "$DIFF_PCT" ]; then
              export DIFF_HISTORY_FILE=badges/history/diff-coverage-history-${SAFE_BRANCH}.json
              node -e "const fs=require('fs');const p=process.env.DIFF_HISTORY_FILE;const val=parseFloat(process.env.DIFF_PCT_VAL);let d=[];try{d=JSON.parse(fs.readFileSync(p,'utf8'));}catch{}d.push({t:Math.floor(Date.now()/1000),pct:val});d=d.slice(-199);fs.writeFileSync(p,JSON.stringify(d,null,2));" DIFF_PCT_VAL="$DIFF_PCT"
            fi
          fi
          if [ -f combined-coverage/coverage-badge.json ]; then
            cp combined-coverage/coverage-badge.json badges/coverage-badge.json
            # Also store a branch-qualified copy for PR delta base comparisons
            cp combined-coverage/coverage-badge.json "badges/coverage-badge-${SAFE_BRANCH}.json" || true
          fi
          if [ -f combined-coverage/coverage-gate-badge.json ]; then
            cp combined-coverage/coverage-gate-badge.json badges/coverage-gate-badge.json
          fi
          if [ -f sonar-qg-badge.json ]; then
            cp sonar-qg-badge.json badges/sonar-quality-gate-badge.json
          fi
          if [ -f diff-coverage/diff-coverage-badge.json ]; then
            cp diff-coverage/diff-coverage-badge.json badges/diff-coverage-badge.json
          fi
          BUILD_STATUS="${{ needs['build-backend'].result }}-${{ needs['build-frontend'].result }}"
          if [ "$BUILD_STATUS" = "success-success" ]; then COLOR=green; MSG=success; else COLOR=red; MSG=fail; fi
            echo "{ \"schemaVersion\":1, \"label\":\"build\", \"message\":\"${MSG}\", \"color\":\"${COLOR}\" }" > badges/build-status-badge.json
          if [ -f combined-coverage/coverage-metrics.json ]; then
            export HISTORY_FILE=badges/history/coverage-history-${SAFE_BRANCH}.json
            LATEST_FILE=badges/history/coverage-latest-${SAFE_BRANCH}.json
            METRICS=$(cat combined-coverage/coverage-metrics.json)
            echo "$METRICS" > "$LATEST_FILE"
            node -e "const fs=require('fs');const p=process.env.HISTORY_FILE;const m=JSON.parse(fs.readFileSync('combined-coverage/coverage-metrics.json','utf8'));let d=[];try{d=JSON.parse(fs.readFileSync(p,'utf8'));}catch{}d.push({t:Math.floor(Date.now()/1000),avg:m.avg,pass:m.pass});d=d.slice(-199);fs.writeFileSync(p, JSON.stringify(d,null,2));"
          fi
          if git status --porcelain | grep -q .; then
            git config user.email "github-actions[bot]@users.noreply.github.com"
            git config user.name "github-actions[bot]"
            git add badges
            git commit -m "chore(badges): update badges for ${GITHUB_REF_NAME}" || echo "Nothing to commit"
            # Fetch remote 'badges' to have an up-to-date ref for --force-with-lease; ignore if it doesn't exist yet
            git fetch --depth=1 origin badges || true
            # Attempt a normal push first (fast-forward expected most of the time). If rejected, retry with --force-with-lease, then --force as last resort.
            if ! git push origin HEAD:badges; then
              echo "Non-fast-forward push rejected. Retrying with --force-with-lease.";
              if ! git push --force-with-lease=origin/badges origin HEAD:badges; then
                echo "--force-with-lease failed (possibly branch created in parallel). Falling back to --force (may overwrite last badge snapshot).";
                git push --force origin HEAD:badges;
              fi
            fi
          else
            echo "No badge changes to commit"
          fi
      - name: PR Coverage Delta Comment
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        env:
          CURRENT_AVG: ${{ needs['coverage-gate'].outputs.coverage_avg }}
          GATE_STATUS: ${{ needs['coverage-gate'].outputs.coverage_gate }}
          REPO_FULL: ${{ github.repository }}
          DIFF_PCT: ${{ needs['diff-coverage'].outputs.diff_pct }}
          DIFF_PASS: ${{ needs['diff-coverage'].outputs.diff_pass }}
        with:
          script: |
            const marker='<!-- coverage-delta -->';
            const safeNumber = (val) => { const n = parseFloat(val); return Number.isFinite(n) ? n : null; };
            let currentRaw = process.env.CURRENT_AVG;
            if(currentRaw && /^(nan|infinity)$/i.test(currentRaw.trim())) currentRaw='';
            const currentNum = safeNumber(currentRaw);
            const baseRef = context.payload.pull_request.base.ref; // base branch
            const safeBase = baseRef.replace(/[\\/]/g,'-').toLowerCase();
            const url = `https://raw.githubusercontent.com/${process.env.REPO_FULL}/badges/badges/coverage-badge-${safeBase}.json`;
            let baseVal = null;
            try {
              const resp = await fetch(url);
              if(resp.ok){
                const json = await resp.json();
                baseVal = safeNumber((json.message||'').replace('%',''));
              }
            } catch(e) { /* ignore fetch errors */ }
            let deltaVal = null; let symbol='';
            if(currentNum!=null && baseVal!=null){
              deltaVal = currentNum - baseVal;
              symbol = deltaVal>0?'▲': deltaVal<0?'▼':'=';
            }
            const gateStatus = (process.env.GATE_STATUS || '').trim();
            const gateDisplay = gateStatus ? gateStatus : 'unknown';
            const currentDisplay = currentNum!=null ? currentNum.toFixed(2)+'%' : 'unavailable';
            const baseDisplay = baseVal!=null ? baseVal.toFixed(2)+'%' : 'unavailable';
            const deltaDisplay = (deltaVal==null? 'n/a' : `${symbol} ${deltaVal.toFixed(2)}%`);
            const diffPctRaw = safeNumber(process.env.DIFF_PCT);
            const diffPctDisplay = diffPctRaw!=null ? diffPctRaw.toFixed(2)+'%' : 'n/a';
            const diffPassEnv = process.env.DIFF_PASS;
            const diffPassDisplay = diffPctRaw==null ? 'n/a' : (diffPassEnv === 'true' ? 'pass' : 'fail');
            const bodyContent = `### Coverage Delta\nCurrent (PR): **${currentDisplay}**\nBase (${baseRef}): **${baseDisplay}**\nDelta: **${deltaDisplay}**\nGate (>=80%): **${gateDisplay}**`;
            const extended = bodyContent + `\nDiff Coverage (>=80%): **${diffPctDisplay} (${diffPassDisplay})**`;
            const { data: comments } = await github.rest.issues.listComments({ ...context.repo, issue_number: context.issue.number });
            const existing = comments.find(c=> c.body && c.body.includes(marker));
            if(existing){
              await github.rest.issues.updateComment({ ...context.repo, comment_id: existing.id, body: `${marker}\n${extended}` });
            } else {
              await github.rest.issues.createComment({ ...context.repo, issue_number: context.issue.number, body: `${marker}\n${extended}` });
            }
